{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609bcc26",
   "metadata": {},
   "source": [
    "# Assignment 2 - Feature extraction and classification\n",
    "\n",
    "In this assignment, you are expected to\n",
    "\n",
    "(1) extract global features from a publicly available dataset with one of the pre-trained neural networks available in pytorch, \n",
    "\n",
    "and \n",
    "\n",
    "(2) classify the dataset using the traditional k-Neural Neighbours classifier.\n",
    "\n",
    "You are also asked to implement k-fold cross-validation to evaluate your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b394f7",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load needed packages\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838957a",
   "metadata": {},
   "source": [
    "When working with Pytorch, dataloader() is a must to know function.\n",
    "\n",
    "Read more about this function and the parameters it accepts in https://blog.paperspace.com/dataloaders-abstractions-pytorch/ ;\n",
    "\n",
    "DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=None,\n",
    "    pin_memory=False,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7db27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2320b0",
   "metadata": {},
   "source": [
    "The variable transform encapsulates the needed transformations of our data\n",
    "\n",
    "Read more about transforms in https://blog.paperspace.com/dataloaders-abstractions-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3daee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # resize\n",
    "    transforms.Resize(32),\n",
    "    # center-crop\n",
    "    transforms.CenterCrop(32),\n",
    "    # to-tensor\n",
    "    transforms.ToTensor(),\n",
    "    # normalize\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d746beb",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f0e38",
   "metadata": {},
   "source": [
    "# INPUT DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f4cd8",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ea732",
   "metadata": {},
   "source": [
    "Load your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example solution for the CIFAR dataset - Please, select the one you worked with in Assignment 1\n",
    "dataset = 'CIFAR10'\n",
    "classes = ('plane', 'car', 'bird', \n",
    "           'cat','deer', 'dog', 'frog', \n",
    "           'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb189026",
   "metadata": {},
   "source": [
    "## Exercise: Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57aaaa8",
   "metadata": {},
   "source": [
    "### Train - Test Split\n",
    "\n",
    "Write a function **train_test_split(dataset, ratio)** which takes a dataset as an input and returns two datasets one for training and another for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset, ratio):\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return training_data,testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f7feb",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f160f",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION\n",
    "\n",
    "Extract descriptros from the images in your train and test dataset. The dataset split should remain the same for all the experiments if you want to be fair when comparing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f0878",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fccdb",
   "metadata": {},
   "source": [
    "## Exercise: Feature 1 - RGB descriptros\n",
    "\n",
    "Following the code you implement in Assignment 1, extract R, G, and B descriptros from the images and concatenate them to create a 1D feature vector of 24 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f654967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51372d11",
   "metadata": {},
   "source": [
    "## Exercise: Feature 2 - Extract descriptors using pre-traind networks\n",
    "\n",
    "Load pretrained a network to extract global features from the images. \n",
    "We will use the values of the last fully connected layer of the deep network as a descriptor, i.e. we will remove the last fully-connected layer. Therefore, after feed-fowarding the input through the network, we save the output as the descriptor of the image.\n",
    "\n",
    "You can use different networks for this purpose.\n",
    "\n",
    "Reading material to start with;\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#sphx-glr-beginner-transfer-learning-tutorial-py\n",
    "\n",
    "https://medium.com/analytics-vidhya/cnn-transfer-learning-with-vgg-16-and-resnet-50-feature-extraction-for-image-retrieval-with-keras-53320c580853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# name of the model you wish to use - it should be selected from this list\n",
    "# [resnet, alexnet, vgg, squeezenet, densenet, inception]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8e832",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599bb2b",
   "metadata": {},
   "source": [
    "# PERFORMANCE EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304d19d",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a59fdf",
   "metadata": {},
   "source": [
    "## Exercise: Error function\n",
    "\n",
    "Implement a function to evaluate the accuracy of your prediction. \n",
    "We will rely on the evaluation metric accuracy.\n",
    "\n",
    "You are suggested to also use f-score, recall and precision. Have a look at https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return accuracy_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549727ac",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b447784",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST YOUR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c6375",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab251607",
   "metadata": {},
   "source": [
    "## Exercise: k Nearest Neighbour model\n",
    "\n",
    "Apply the classifier with different values of k (number of nearest neighbours) to the two sets of previously extracted descriptors (RGB and CNN features) and evaluate the performance of your models (accuracy).\n",
    "\n",
    "You can have a look at the documentation to understand the parameters that define the learning of the model,\n",
    "https://scikit-learn.org/stable/modules/neighbors.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90aba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your k-NN - play with the value of the parameters to see how the model performs\n",
    "kvalue_list = [2,4,6,10,15] \n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e94c23",
   "metadata": {},
   "source": [
    "## Exercise: Visualize results \n",
    "\n",
    "Steps to follow:\n",
    "\n",
    "1) Apply PCA and select the 2 first principal components to represent each sample.\n",
    "\n",
    "2) Plot the samples with dots. Use a colour per class. \n",
    "\n",
    "3) Plot the samples again but with empty filled circles. Use the color of the class predicted per sample (misclassifications will make the colours not coincide).\n",
    "\n",
    "You can do this for (1) training and (2) test set. In (1) you can see how well the method fits the training data and (2) will give you an idea of the misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77cbfb5",
   "metadata": {},
   "source": [
    "## Exercise: kNN with k-Fold cross-validation\n",
    "\n",
    "Assess the performance of your implemented kNN using k-Fold cross-validation. \n",
    "\n",
    "Run your implemented function evaluating for k (fold) = 2, 5 and 10. You can rely on the kNN that performed best in the previous exercises.\n",
    "Report the average accuracy and the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f603d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba435dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUGGESTION ON HOW TO PRESENT PERFORMANCE OF YOUR KFOLD CROSS VALIDATION ANALYSIS\n",
    "\n",
    "print('Summary results:')\n",
    "print(' ')\n",
    "print(' ')\n",
    "for i,k in enumerate(k_list):\n",
    "    print(k,'-fold cross validation:')  \n",
    "    print('Accuracies per fold: ', avg_acc_list[i]) \n",
    "    \n",
    "    avg_acc = round(sum(avg_acc_list[i])/k,2)\n",
    "    std_list= round(np.std(avg_acc_list[i]),2)\n",
    "    print('Average accuracy: ', avg_acc,'+-', std_list) \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf70eb",
   "metadata": {},
   "source": [
    "### [Optional] Exercise: further explore by: \n",
    "- implement other classifiers such as SVM or Random Forest, \n",
    "- extract other descriptors from the images such as objects or other local features,\n",
    "- implement the evaluation metrics: recall, precission and f-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b69360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
