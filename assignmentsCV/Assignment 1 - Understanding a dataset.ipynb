{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ac48ce",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you will explore a dataset. \n",
    "\n",
    "You can choose a dataset to follow this assignment from the list of available datasets in https://pytorch.org/vision/stable/datasets.html . Given that you will be asked to extract RGB descriptros, you should select 3-channel images.\n",
    "\n",
    "Comment your code and indicate what the different instructions are doing and what you are showing and printing. \n",
    "When printing figures do not forget about the title, x and y labels. The font size should be matching the text size of the text in your report. \n",
    "Do not forget to add legends to the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load needed packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# include packages you will be using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e71845",
   "metadata": {},
   "source": [
    "### Exercise: Load data\n",
    "\n",
    "Load the dataset. \n",
    "Print how many samples, classes, and shape of an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9da0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "dataset = torchvision.datasets. ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3925c",
   "metadata": {},
   "source": [
    "### Exercise: Quantify dataset\n",
    "\n",
    "1) Print the number of samples per category.\n",
    "\n",
    "2) Plot these number using a bar plot.\n",
    "\n",
    "Reflection: Are you working with a balanced dataset? unbalanced dataset? Are there majoritarian classes? Do you think this will affect the later analysis and training of your models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7d688",
   "metadata": {},
   "source": [
    "### Exercise: Visualize images\n",
    "\n",
    "Create a figure with n x 4 images, one per category of your dataset. The value of n will depend on the number of categories of your selected dataset.\n",
    "As the title of each of the images in your figure, indicate the category it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe15647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac727d",
   "metadata": {},
   "source": [
    "### Exercise: RGB feature extraction\n",
    "\n",
    "Extract RGB values from the image as three lists. 8 values per channel. To do so, you can compute the histogram of each channel with 8 bits, and then concatenate those values. The resulting descriptor will have 24 values (8 values per channel). This feature vector is the descriptor of an images in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c61c2",
   "metadata": {},
   "source": [
    "### Exercise: Correlation among samples of the different categories\n",
    "\n",
    "After extracting the RGB descriptors, you have now descriptors and labels (each category represents a label). \n",
    "\n",
    "Compute the inter-class and intra-class variability of your dataset. \n",
    "\n",
    "Hints:\n",
    "\n",
    "- For intra-class correlation you can use the implementation from the pingouin package,\n",
    "https://pingouin-stats.org/generated/pingouin.intraclass_corr.html\n",
    "\n",
    "- For inter-class correlation you can compute the variability among the descriptors of the samples that belong to a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d265983",
   "metadata": {},
   "source": [
    "The Silhouette score is used to assess the performance of using unsupervised machine learning (clustering). We can also use it here to assess the compactness of the extracted descriptors.\n",
    "\n",
    "You can use the function available in Sklearn;\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f631479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c34c1",
   "metadata": {},
   "source": [
    "Reflection: Do these metrics help you assess the degree of similarity among the samples of a category? what about among categories? What can you deduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd728d06",
   "metadata": {},
   "source": [
    "### Exercise: Dimensionality reduction for visualization \n",
    "\n",
    "We can visualize 2- or 3-dimensional spaces. \n",
    "For this reason, you need to reduce dimensionality. \n",
    "\n",
    "In this exercise you are asked to use PCA for reducing dimensionality.\n",
    "\n",
    "Link to function to apply PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "Create the following two figures:\n",
    "\n",
    "1) Rely on the first 2 principal components to plot the samples of your dataset. \n",
    "\n",
    "2) Rely on the first 3 principal components to create a 3D plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79009c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061bd12",
   "metadata": {},
   "source": [
    "### Exercise: Reflection\n",
    "\n",
    "Reflect on the following questions. Your answers can be implemented in the report for the practical.\n",
    "\n",
    "    - Will you obtain the same visualisation in the feature space for diffrent extracted features?\n",
    "    \n",
    "    - Are the classes distinguishable on the feature space when relaying on PCA over RGB?\n",
    "    \n",
    "    - What other visualization could you include to better describe your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c64ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your reflection here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051c7a1",
   "metadata": {},
   "source": [
    "### [Optional] Exercise: Repeat experiments with different image descriptros\n",
    "\n",
    "e.g. \n",
    "- Harris Corner Detection\n",
    "\n",
    "- Shi-Tomasi Corner Detector and Good Features to Track\n",
    "\n",
    "- Scale-Invariant Feature Transform (SIFT)\n",
    "\n",
    "- Speeded-up robust features (SURF)\n",
    "\n",
    "- Features from Accelerated Segment Test (FAST)\n",
    "\n",
    "- Blob Detectors With LoG, DoG, and DoH\n",
    "\n",
    "If you have OpenCV installed you can follow this examples,\n",
    "https://automaticaddison.com/image-feature-detection-description-and-matching-in-opencv/\n",
    "\n",
    "When using Scikit-image,\n",
    "https://scikit-image.org/docs/dev/api/skimage.feature.html?highlight=hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c74d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
