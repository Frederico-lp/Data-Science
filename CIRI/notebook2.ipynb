{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # to-tensor\n",
    "    transforms.ToTensor(),\n",
    "    # resize\n",
    "    transforms.Resize(128),\n",
    "    # center-crop\n",
    "    transforms.CenterCrop(128),\n",
    "    # normalize\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]),\n",
    "])\n",
    "\n",
    "inception_preprocess = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incidents = dataset.IncidentsDataset(\"Incidents-subset\", transform=inception_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_indices, test_indices, _, _ = train_test_split(range(incidents.__len__()), incidents.targets, stratify=incidents.targets, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_indices), len(test_indices), incidents.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_split = Subset(incidents, train_indices)\n",
    "test_split = Subset(incidents, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_split, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(incidents, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nSamples = incidents.__len__()\n",
    "nClasses = len(incidents.labels)\n",
    "imgShape = incidents.__getitem__(0)[0].shape\n",
    "\n",
    "print(\"Number of samples: \", nSamples)\n",
    "print(\"Number of classes: \", nClasses)\n",
    "print(\"Shape of an image: \", imgShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target, counts = np.unique(incidents.targets, return_counts=True)\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.bar(incidents.labels[target], counts) #, width=1, edgecolor=\"white\", linewidth=.7)\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(nClasses, 4), axes_pad=(1, .3))\n",
    "\n",
    "images = []\n",
    "\n",
    "for n in np.arange(nClasses):\n",
    "    for i in range(4):\n",
    "        img = incidents.get_item_with_target(n, i)\n",
    "        idx = n*4+i\n",
    "        grid[idx].imshow(img.permute(1, 2, 0))\n",
    "        grid[idx].set_title(incidents.labels[n])\n",
    "        grid[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, num_epochs, train_loader, test_loader, criterion, optimizer):\n",
    "    start = time.time()\n",
    "    accuracy_history = {'train': [], 'test': []}\n",
    "    loss_history = {'train': [], 'test': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        running_loss_train, running_loss_test = 0.0, 0.0\n",
    "        running_corrects_train, running_corrects_test = 0, 0\n",
    "\n",
    "        print(\"Training...\")\n",
    "        model.train()  # Put the network in train mode\n",
    "        for i, (x_batch, y_batch) in enumerate(tqdm(train_loader)):\n",
    "            x_batch = x_batch.to(device)  # Move the data to the device that is used\n",
    "            y_batch = y_batch.type(torch.LongTensor) # <---- Here (casting)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            # output = model(x_batch)\n",
    "\n",
    "            # Required for inception model\n",
    "            output, _ = model(x_batch)\n",
    "            loss_train = criterion(output, y_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()  # Set all currenly stored gradients to zero\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute relevant metrics\n",
    "            _, preds = torch.max(output, dim=1)  # Get the labels with highest output probability\n",
    "\n",
    "            running_loss_train += loss_train.item() * x_batch.size(0)\n",
    "            running_corrects_train += torch.sum(preds == y_batch.data)\n",
    "\n",
    "            elapsed = time.time() - start  # Keep track of how much time has elapsed\n",
    "\n",
    "        print(\"Evaluating...\")\n",
    "        model.eval()  # Put the network in eval mode\n",
    "        for i, (x_batch, y_batch) in enumerate(test_loader):\n",
    "            x_batch = x_batch.to(device)  # Move the data to the device that is used\n",
    "            y_batch = y_batch.type(torch.LongTensor) # <---- Here (casting)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            output = model(x_batch)\n",
    "            loss_test = criterion(output, y_batch)\n",
    "            _, preds = torch.max(output, dim=1)\n",
    "\n",
    "            running_loss_test += loss_test.item() * x_batch.size(0)\n",
    "            running_corrects_test += torch.sum(preds == y_batch.data)\n",
    "\n",
    "        accuracy_history['train'].append(running_corrects_train/len(train_split))\n",
    "        accuracy_history['test'].append(running_corrects_test/len(test_split))\n",
    "\n",
    "        loss_history['train'].append(running_loss_train)\n",
    "        loss_history['test'].append(running_loss_test)\n",
    "\n",
    "        print(f'Accuracy on the train set: {running_corrects_train / len(train_split):.3f}. Loss: {running_loss_train:.3f}')\n",
    "        print(f'Accuracy on the test set: {running_corrects_test / len(test_split):.3f}. Loss: {running_loss_test:.3f}')\n",
    "\n",
    "    return model, accuracy_history, loss_history, time.time() - start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_curves(curves, model_name, mode, num_epochs, num_splits):\n",
    "    train_curves, test_curves = np.zeros((num_splits, num_epochs)), np.zeros((num_splits, num_epochs))\n",
    "\n",
    "    for i, curve in enumerate(curves):\n",
    "        train, test = curve['train'], curve['test']\n",
    "        if mode == \"accuracy\":\n",
    "            train = [train[i].item() for i in range(train.__len__())]\n",
    "            test = [test[i].item() for i in range(test.__len__())]\n",
    "\n",
    "        for j, (train_value, test_value) in enumerate(zip(train, test)):\n",
    "            train_curves[i, j] = train_value\n",
    "            test_curves[i, j] = test_value\n",
    "\n",
    "    dir_name = f\"{model_name}\"\n",
    "    dir_exists = os.path.exists(dir_name)\n",
    "\n",
    "    if not dir_exists:\n",
    "        os.mkdir(dir_name)\n",
    "    np.save(f\"{dir_name}/{model_name}_train_{mode}.npy\", train_curves)\n",
    "    np.save(f\"{dir_name}/{model_name}_test_{mode}.npy\", test_curves)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.inception_v3(weights=models.Inception_V3_Weights)\n",
    "\n",
    "model\n",
    "        # model.fc = torch.nn.Linear(2048, nClasses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "def get_model(name):\n",
    "    if name == \"inception\":\n",
    "        model = models.inception_v3(weights=models.Inception_V3_Weights)\n",
    "        model.fc = torch.nn.Linear(2048, nClasses)\n",
    "    elif name == \"resnet\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights)\n",
    "        model.fc = torch.nn.Linear(2048, nClasses)\n",
    "    elif name == \"mobilenet\":\n",
    "        model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights)\n",
    "        model.classifier[1] = torch.nn.Linear(1280, nClasses)\n",
    "    else:\n",
    "        model = None\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_recall_f1_precision_accuracy_confusion_matrix(model, test_loader):\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            ground_truth.append(labels.numpy())\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "\n",
    "    ground_truth = np.concatenate(ground_truth)\n",
    "    predictions = np.concatenate(predictions)\n",
    "    accuracy = metrics.accuracy_score(ground_truth, predictions)\n",
    "    f1 = metrics.f1_score(ground_truth, predictions, average='weighted')\n",
    "    precision = metrics.precision_score(ground_truth, predictions, average='weighted')\n",
    "    recall = metrics.recall_score(ground_truth, predictions, average='weighted')\n",
    "    confusion_matrix = metrics.confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "    return recall, f1, precision, accuracy, confusion_matrix\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "\n",
    "num_splits = 5\n",
    "kfold = KFold(n_splits=num_splits, shuffle=True)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for model_name in [\"inception\"]:\n",
    "    accuracy_curves = []\n",
    "    loss_curves = []\n",
    "    fold = 0\n",
    "    recalls, f1s, precisions, accuracies, conf_matrices = [], [], [], [], []\n",
    "\n",
    "    for train, test in kfold.split(incidents):\n",
    "        # Creating model, the optimizers and criterion\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = get_model(model_name)\n",
    "        model = model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Splitting data\n",
    "        train_split = Subset(incidents, train)\n",
    "        test_split = Subset(incidents, test)\n",
    "\n",
    "        train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_split, batch_size=batch_size)\n",
    "\n",
    "        # Training the model\n",
    "        model, accuracy_history, loss_history, elapsed_time = train_model(model, num_epochs, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "        # Saving the model and its indices, so its train and test data can be reused\n",
    "        torch.save(model.state_dict(), f\"models/{model.__class__.__name__}_{fold}.pt\")\n",
    "        with open(f\"models/{model.__class__.__name__}_{fold}_indices\", 'w') as indices_file:\n",
    "            indices_file.write(json.dumps({'train': train.tolist(), 'test': test.tolist()}))\n",
    "\n",
    "        # Add all the metrics to lists, so they can be averaged and stored in files\n",
    "        accuracy_curves.append(accuracy_history)\n",
    "        loss_curves.append(loss_history)\n",
    "        fold += 1\n",
    "\n",
    "        recall, f1, precision, accuracy, conf_matrix = get_recall_f1_precision_accuracy_confusion_matrix(model, test_loader)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        precisions.append(precision)\n",
    "        accuracies.append(accuracy)\n",
    "        conf_matrices.append(conf_matrix)\n",
    "\n",
    "    # Saving all the metrics to files\n",
    "    average_metrics = {'recall': sum(recalls)/len(recalls), 'f1': sum(f1s)/len(f1s), 'precision': sum(precisions)/len(precisions), 'accuracy': sum(accuracies)/len(accuracies)}\n",
    "    save_curves(accuracy_curves, model.__class__.__name__, \"accuracy\", num_epochs, num_splits)\n",
    "    save_curves(loss_curves, model.__class__.__name__, \"loss\", num_epochs, num_splits)\n",
    "    np.save(f\"{model.__class__.__name__}/conf_matrix.npy\", np.array(conf_matrices))\n",
    "\n",
    "    with open(f\"{model.__class__.__name__}/metrics.txt\", 'w') as metrics_file:\n",
    "        metrics_file.write(json.dumps(average_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import os\n",
    "#\n",
    "# def save_curves(curves, model_name, pretrained, mode, num_epochs, num_splits):\n",
    "#     train_curves, test_curves = np.zeros((num_splits, num_epochs)), np.zeros((num_splits, num_epochs))\n",
    "#\n",
    "#     for i, curve in enumerate(curves):\n",
    "#         train, test = curve['train'], curve['test']\n",
    "#         if mode == \"accuracy\":\n",
    "#             train = [train[i].item() for i in range(train.__len__())]\n",
    "#             test = [test[i].item() for i in range(test.__len__())]\n",
    "#\n",
    "#         for j, (train_value, test_value) in enumerate(zip(train, test)):\n",
    "#             train_curves[i, j] = train_value\n",
    "#             test_curves[i, j] = test_value\n",
    "#\n",
    "#     dir_name = f\"{model_name}_{int(pretrained)}\"\n",
    "#     dir_exists = os.path.exists(dir_name)\n",
    "#\n",
    "#     if not dir_exists:\n",
    "#         os.mkdir(dir_name)\n",
    "#     np.save(f\"{dir_name}/{model_name}_{int(pretrained)}_train_{mode}.npy\", train_curves)\n",
    "#     np.save(f\"{dir_name}/{model_name}_{int(pretrained)}_test_{mode}.npy\", test_curves)\n",
    "\n",
    "\n",
    "# save_curves(accuracy_curves, model.__class__.__name__, False, \"accuracy\", num_epochs, num_splits)\n",
    "# save_curves(loss_curves, model.__class__.__name__, False, \"loss\", num_epochs, num_splits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = open(\"ResNet_0/dict.txt\",\"w\")\n",
    "# f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metrics_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.load(\"ResNet/conf_matrix.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e511838c1e57aaa348af65028b1d0e807fc0ba78c128e77bcd38a63295926b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}